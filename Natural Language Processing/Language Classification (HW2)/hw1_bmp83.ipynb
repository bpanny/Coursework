{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2, The Politeness Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import nltk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, make_scorer, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\benja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\benja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') # this is needed to use NLTK's `word_tokenize` function\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "polite = pd.read_csv('politeness_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of           id                                               text  polite\n",
       "0       1331  Try to add an `import pycuda` line at the top ...       1\n",
       "1     196858  Hello, our project has begun to fall a little ...       1\n",
       "2      25622  Picking up your challenge. You a big fan of sk...       0\n",
       "3       4161  @Herbert: Still I think your answer is very co...       1\n",
       "4     526013  Thanks for continuing to look over the article...       1\n",
       "...      ...                                                ...     ...\n",
       "4927    6485  You never mentioned how far it is to work? How...       0\n",
       "4928    3637  Why are the results bad? Can you elaborate on ...       0\n",
       "4929     765  Thank you, after some experimenting, this seem...       1\n",
       "4930     991  Why are you using that in the first place? Why...       0\n",
       "4931    6458  Why on earth would that make for bad chicken s...       0\n",
       "\n",
       "[4932 rows x 3 columns]>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polite.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=polite.text\n",
    "y=polite.polite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1_score': make_scorer(f1_score)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_bow = Pipeline([('vec',CountVectorizer()),\n",
    "                     ('lr', LogisticRegression(C = 1, penalty='l2',solver='saga',max_iter=1000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_tfidf = Pipeline([('vec',TfidfVectorizer()), \n",
    "                       ('lr', LogisticRegression(C = 1, penalty='l2',solver='saga',max_iter=1000))])\n",
    "pipe_binary = Pipeline([('vec',CountVectorizer(binary=True)), \n",
    "                       ('lr', LogisticRegression(C = 1, penalty='l2',solver='saga',max_iter=1000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_bow = cross_validate(pipe_bow, x, y, cv=5, scoring = scoring)\n",
    "cv_tfidf = cross_validate(pipe_tfidf, x, y, cv=5, scoring = scoring)\n",
    "cv_binary = cross_validate(pipe_binary, x, y, cv=5, scoring = scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>binary</th>\n",
       "      <td>0.326193</td>\n",
       "      <td>0.023488</td>\n",
       "      <td>0.701542</td>\n",
       "      <td>0.703966</td>\n",
       "      <td>0.695873</td>\n",
       "      <td>0.699767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bow</th>\n",
       "      <td>0.627263</td>\n",
       "      <td>0.022621</td>\n",
       "      <td>0.696880</td>\n",
       "      <td>0.699391</td>\n",
       "      <td>0.691004</td>\n",
       "      <td>0.695107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>0.101053</td>\n",
       "      <td>0.021685</td>\n",
       "      <td>0.710667</td>\n",
       "      <td>0.704289</td>\n",
       "      <td>0.727091</td>\n",
       "      <td>0.715381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fit_time  score_time  test_accuracy  test_precision  test_recall  \\\n",
       "model                                                                      \n",
       "binary  0.326193    0.023488       0.701542        0.703966     0.695873   \n",
       "bow     0.627263    0.022621       0.696880        0.699391     0.691004   \n",
       "tfidf   0.101053    0.021685       0.710667        0.704289     0.727091   \n",
       "\n",
       "        test_f1_score  \n",
       "model                  \n",
       "binary       0.699767  \n",
       "bow          0.695107  \n",
       "tfidf        0.715381  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_models = pd.concat([pd.DataFrame(cv_bow), pd.DataFrame(cv_tfidf), pd.DataFrame(cv_binary)])\n",
    "lr_models['model'] = np.repeat(['bow','tfidf','binary'], 5)\n",
    "lr_models.groupby('model').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each feature or change in input text processing:\n",
    "Describe your motivation for including the feature\n",
    "Discussion of results: Did it improve performance or not? (Either result is fine. It is not necessary to beat logistic regression with unigram features.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My models are as follows:\n",
    "\n",
    "- Baseline model, L2 normalized logistic regression with word counts as features\n",
    "- Tf-idf model, L2 normalized logistic regression with tf-idf weighted word features. My motivation for attempting this is that it will downweight or outright eliminate unimportant, highly frequent words (e.g., 'the'), \"biasing\" the model estimation process towards rarer, reasonably more informative words.\n",
    "- Binary model, same as the baseline model except with binary word presence indicators instead of counts. My motivation for attempting this is that it is a simpler model than using counts. For instance, it may be beneficial to indicate whether or word occurs vs. how many times it occurs, because the number of times a word appears may not scale with an increase in odds that the text is polite or impolite. Therefore, this would add some noise to the model estimation process.  \n",
    "- Other ideas: obtain or make a \"politeness\" lexicon indicator. Things that I know for certain should be correlated with politeness/impoliteness, e.g., the use of the word `please` or `thank you` bigram or the use of the word `stupid` or a `you suck` bigram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a feature-based model of your choice:\n",
    "\n",
    "List the top 2 most informative features that are mostly strongly positively and negatively associated with politeness. Discuss if you find these surprising and any other comments you might have. You may adapt code provided by the instructor in the Naive Bayes example (notebook here), use another source online, or write your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will give this information for my TF-IDF logistic regression model because it performed the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1:\n",
      "thanks 5.645505067725689\n",
      "could 3.348128349104262\n",
      "\n",
      "Class 0:\n",
      "why 6.488065432838999\n",
      "homework 2.7116534979864335\n"
     ]
    }
   ],
   "source": [
    "pipe_tfidf.fit(x, y)\n",
    "\n",
    "# Define the most_informative_features function\n",
    "def most_informative_features(vectorizer, classifier, n=10):\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    topn_class1 = sorted(zip(classifier.coef_[0], feature_names))[-n:]\n",
    "    topn_class0 = sorted(zip(-classifier.coef_[0], feature_names))[-n:]\n",
    "    \n",
    "    print(\"Class 1:\")\n",
    "    for coef, feat in reversed(topn_class1):\n",
    "        print(feat, coef)\n",
    "        \n",
    "    print(\"\\nClass 0:\")\n",
    "    for coef, feat in reversed(topn_class0):\n",
    "        print(feat, coef)\n",
    "\n",
    "\n",
    "most_informative_features(pipe_tfidf.named_steps['vec'], pipe_tfidf.named_steps['lr'], n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That `thanks` is important to politeness is unsurprising. `Could` is also possibly unsurprising, because it can be the start of a polite question.\n",
    "\n",
    "That `why` is important to impoliteness is interesting because one connotation of this is that `why` questions on StackOverflow usually come from questioning the judgment of the questioner by the answerer. That `homework` is also predictive of impoliteness is interesting because Stackoverflow is a website for people to try answering their own problems first, failing, and then saying why they are stuck. That someone might mention homework in an impolite response might mean they were responding to someone curtly about doing their own homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do an error analysis. Provide a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2106  360]\n",
      " [ 339 2127]]\n"
     ]
    }
   ],
   "source": [
    "pred_y = pipe_tfidf.predict(x)\n",
    "cm = confusion_matrix(y, pred_y)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('Ground Truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is about 70% correct, as our accuracy metric indicates. The errors are split approximately 50/50 between false negatives and false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample multiple examples from both false negatives and false positives. Do you see any patterns in these errors? How might these errors be addressed with different features or if the system could understand something else? (You donâ€™t have to implement these, just speculate.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Negatives:\n",
      "What are you trying to say? You want a Registry Editor?\n",
      "Negative Words? False\n",
      "Positive Words? False\n",
      "Not sure what you are referring to when you say you need an SQL query builder for \"Python\". Do you mean to say you need an ORM like SQLAlchemy (http://www.sqlalchemy.org/) to connect with databases without having to write SQL statements yourself?\n",
      "Negative Words? True\n",
      "Positive Words? True\n",
      "I confess, no. What's exactly to be read in the docs you are referring to?\n",
      "Negative Words? True\n",
      "Positive Words? False\n",
      "I read the diff upside down or something... Glad someone is keeping an eye on me :) I'm mainly doing stuff over here <url> these days, what are you up to currently? Still concentrating on the Ui Imair?\n",
      "Negative Words? True\n",
      "Positive Words? True\n",
      "What version of bash are you using? Is it 4.x or 3.x?\n",
      "Negative Words? False\n",
      "Positive Words? False\n",
      "At what point in this process did you discover the MBP was unplugged? Is the problem continuing to happen after the MBP is fully recharged?\n",
      "Negative Words? True\n",
      "Positive Words? True\n",
      "How are `g_rx_buffer` and `BYTE` defined?  What compiler are you using?\n",
      "Negative Words? False\n",
      "Positive Words? False\n",
      "What would stop the algorithm from just producing a regular expression that is the \"or\" of all the possible substrings?  Or would you be comfortable with this regular expression from being produced?\n",
      "Negative Words? False\n",
      "Positive Words? True\n",
      "Ditto \"look professional\". What does that mean to you, exactly?\n",
      "Negative Words? False\n",
      "Positive Words? False\n",
      "@Ivo Wetzel So, you are saying there is not way to get all objects attributes and values ? Or to convert such object to an associative array ?\n",
      "Negative Words? True\n",
      "Positive Words? False\n",
      "\n",
      "False Positives:\n",
      "You could specify whether you need an introduction on applied statistics, or one on (theoretical) statistical inference. I.e., do you want the framework of testing, regression and ANOVA explained or do you want to know what the central limit theorem and the inequality of Chebiyshev have to do with the weak law of large numbers?\n",
      "Negative Words? True\n",
      "Positive Words? True\n",
      "I guess this could lead to another set of advertising answers. There are a good range of vendors providing high quality services in this industry, but you might want to update your question with region, country etc?\n",
      "Negative Words? True\n",
      "Positive Words? True\n",
      "@There: That's a lot of code to wade through.  Are you saying you can't possibly simplify it in any further?\n",
      "Negative Words? False\n",
      "Positive Words? True\n",
      "Re: <url> and <url>, if you think they are better off as redirects to the suburb/town rather than substubs on the lakes with a <nowiki><person></nowiki> tagline, you only need to overwrite the article with a redirect (or revert to a previous version that was a redirect), leaving the substub in the article history. How come you speedied them before redirecting?\n",
      "Negative Words? True\n",
      "Positive Words? True\n",
      "Sorry @klox I don't understand. Could you explain a bit more?\n",
      "Negative Words? True\n",
      "Positive Words? False\n",
      "There cant be a general solution. What do you do when the stack has 10 entries and you need to output a number, but the last number hasnt arrived yet?\n",
      "Negative Words? False\n",
      "Positive Words? True\n",
      "Hi, although I agree with you, please check the following <url> in process. Why can't the darn thing work, in the first place?\n",
      "Negative Words? False\n",
      "Positive Words? True\n",
      "If the ads are script elements, does it really matter where you place them? Perhaps you can give an example?\n",
      "Negative Words? True\n",
      "Positive Words? True\n",
      "The sources are ref'd in the article. Can you be more specific?\n",
      "Negative Words? False\n",
      "Positive Words? False\n",
      "Further to what Stefan said, the tocloft package might be sensitive to other things you have in your preamble.  Could you post a [minimum working example](http://meta.tex.stackexchange.com/questions/228/ive-just-been-told-i-have-to-write-a-minimal-example-what-is-that), please?\n",
      "Negative Words? True\n",
      "Positive Words? True\n",
      "The number of false negative examples with a top 10 informative negative word was 5 out of 10\n",
      "The number of false negative examples with a top 10 informative positive words was 4 out of 10\n",
      "The number of false positive examples with a top 10 informative negative words was 6 out of 10\n",
      "The number of false positive examples with a top 10 informative positive words was 8 out of 10\n"
     ]
    }
   ],
   "source": [
    "def get_misses(outcome, outcome_hat, text_data):\n",
    "    false_negatives = [i for i, outcome in enumerate(outcome) if ((outcome == 1) & (outcome_hat[i] == 0))]\n",
    "    false_positives = [i for i, outcome in enumerate(outcome) if ((outcome == 0) & (outcome_hat[i] == 1))]\n",
    "    top10_positive = ['thanks', 'could', 'hi', 'can', 'for', 'thank', 'help', 'great', 'good', 'would']\n",
    "    top10_negative = ['why', 'homework', 'really', 'not', 'don', 'who', 'wikipedia', 'what', 'shouldn', 'no']\n",
    "    neg_in_fn = 0\n",
    "    pos_in_fn = 0\n",
    "    neg_in_fp = 0\n",
    "    pos_in_fp = 0\n",
    "\n",
    "    print(\"False Negatives:\")\n",
    "    for i in false_negatives[0:10]:\n",
    "        print(text_data[i])\n",
    "        print('Negative Words? ' + str(any(word in text_data[i] for word in top10_negative)))\n",
    "        if any(word in text_data[i] for word in top10_negative):\n",
    "            neg_in_fn += 1\n",
    "        print('Positive Words? ' + str(any(word in text_data[i] for word in top10_positive)))\n",
    "        if any(word in text_data[i] for word in top10_positive):\n",
    "            pos_in_fn += 1\n",
    "\n",
    "\n",
    "    print(\"\\nFalse Positives:\")\n",
    "    for i in false_positives[0:10]:\n",
    "        print(text_data[i])\n",
    "        print('Negative Words? ' + str(any(word in text_data[i] for word in top10_negative)))\n",
    "        print('Positive Words? ' + str(any(word in text_data[i] for word in top10_positive)))\n",
    "        if any(word in text_data[i] for word in top10_negative):\n",
    "            neg_in_fp += 1\n",
    "        if any(word in text_data[i] for word in top10_positive):\n",
    "            pos_in_fp += 1\n",
    "    \n",
    "    print(f'The number of false negative examples with a top 10 informative negative word was {neg_in_fn} out of 10')\n",
    "    print(f'The number of false negative examples with a top 10 informative positive words was {pos_in_fn} out of 10')\n",
    "    print(f'The number of false positive examples with a top 10 informative negative words was {neg_in_fp} out of 10')\n",
    "    print(f'The number of false positive examples with a top 10 informative positive words was {pos_in_fp} out of 10')\n",
    "\n",
    "get_misses(y, pred_y, x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 8 out of 10 false positive examples, there was a positive word that was in the top10 most informative positive words. \n",
    "In 5 out of 10 false negative examples, there was a negative word that was in the top10 most informative negative words.\n",
    "\n",
    "At the same time, both false positive examples and false negative examples also had the presence of informative positive and negative words. Two false positive examples contain the words \"can't\", which my tokenizer tokenizes partially into the word 'can'. This is a clear example of how preprocessing can affect the downstream prediction task. If I had included 'can't' as its own, full token, this might've helped the model distinguish between someone saying something polite containing 'can' and someone saying something impolite with 'can't' (e.g., \"can't you do this?\"). \n",
    "\n",
    "Another way that the features could be improved is to use larger n-grams. For instance, even if I use the same tokenizer, it could've helped the model if it saw \"can\" and \"'t\" as a bigram feature compared to \"can\" and \"'t\" as independent and uncorrelated unigram features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will build and evaluate a feedforward neural network that uses pre-trained static word embeddings (word2vec, GloVe, FastText, etc) as input. To represent the document, you can take the average word embeddings of the input sentence or choose another function. You can choose which activation function to use and other hyperparameters. You will again use 5-fold cross validation on the dataset. There is no need for this model to outperform the logistic regression model you made.\n",
    "\n",
    "Tasks for section 2.2\n",
    "Implement a feedforward neural network with static word embeddings as input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [nltk.word_tokenize(sentence) for sentence in x]\n",
    "model = Word2Vec(sentences)\n",
    "def sentence_to_avg_vector(sentence):\n",
    "    words = sentence.split()\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv.key_to_index]\n",
    "    if not word_vectors:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "polite['text_avg_embedding'] = polite['text'].apply(sentence_to_avg_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier(max_iter=1000, random_state=42)\n",
    "\n",
    "nn_x = np.stack(polite['text_avg_embedding'].values)\n",
    "nn_y = polite['polite'].values\n",
    "\n",
    "cv_nn = cross_validate(nn, nn_x, nn_y, cv=5, scoring = scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = pd.DataFrame(cv_nn)\n",
    "nn_model['model'] = np.repeat(['nn'], 5)\n",
    "all_models = pd.concat([lr_models, nn_model])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the report, please provide:\n",
    "\n",
    "Performance scores for this model. Include accuracy as well as precision, recall, and f1-score for the positive (polite) class. This can be an additional row in the table with other performance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>binary</th>\n",
       "      <td>0.326193</td>\n",
       "      <td>0.023488</td>\n",
       "      <td>0.701542</td>\n",
       "      <td>0.703966</td>\n",
       "      <td>0.695873</td>\n",
       "      <td>0.699767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bow</th>\n",
       "      <td>0.627263</td>\n",
       "      <td>0.022621</td>\n",
       "      <td>0.696880</td>\n",
       "      <td>0.699391</td>\n",
       "      <td>0.691004</td>\n",
       "      <td>0.695107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn</th>\n",
       "      <td>3.998432</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.610710</td>\n",
       "      <td>0.614305</td>\n",
       "      <td>0.616010</td>\n",
       "      <td>0.611709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>0.101053</td>\n",
       "      <td>0.021685</td>\n",
       "      <td>0.710667</td>\n",
       "      <td>0.704289</td>\n",
       "      <td>0.727091</td>\n",
       "      <td>0.715381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fit_time  score_time  test_accuracy  test_precision  test_recall  \\\n",
       "model                                                                      \n",
       "binary  0.326193    0.023488       0.701542        0.703966     0.695873   \n",
       "bow     0.627263    0.022621       0.696880        0.699391     0.691004   \n",
       "nn      3.998432    0.006944       0.610710        0.614305     0.616010   \n",
       "tfidf   0.101053    0.021685       0.710667        0.704289     0.727091   \n",
       "\n",
       "        test_f1_score  \n",
       "model                  \n",
       "binary       0.699767  \n",
       "bow          0.695107  \n",
       "nn           0.611709  \n",
       "tfidf        0.715381  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models.groupby('model').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf-idf model is still the best performing model, logistic regression or otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the motivation for any choices you made as far as word embedding types, pretraining dataset, and/or how you represented the document, or if you experimented with multiple of these options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used word2vec because it is an easily understandable way to embed words based on their 'positive' contexts. I also estimated embeddings using the polite dataset using the word2vec algorithm because it was easiest. I then represented each sentence/documents as the average embedding of the words it contains because it was straightforward to do so. These motivations are not very virtuous and it shows in the performance of the neural network, although there are also the architectural factors to consider with regards to the performance. I did not experiment with any other embedding or representation options. However, if I were to experiment with different embeddings, I would find a pre-trained embedding obtained from a larger corpus with documents similar to the one in this dataset (code Q&A forum) or another somewhat conversational corpus. For experimenting with representations, perhaps the sum of embeddings would be a better representation than the averages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the motivation for any choices you made as far as network architecture (number and dimensions of hidden layers) or hyperparameters (learning rate, number of epochs, etc). Note if you experimented with any of these options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't know why I would choose one architecture and set of hyperparameters over another, so I used default parameters (i.e., one hidden layer with `100 neurons` and the `relu` activation function). This is where hyperparameter tuning comes in so let's try that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=MLPClassifier(max_iter=300, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                         &#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.05],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [(50, 50, 50), (50, 100, 50),\n",
       "                                                (10, 10)],\n",
       "                         &#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;adaptive&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;sgd&#x27;, &#x27;adam&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=MLPClassifier(max_iter=300, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                         &#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.05],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [(50, 50, 50), (50, 100, 50),\n",
       "                                                (10, 10)],\n",
       "                         &#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;adaptive&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;sgd&#x27;, &#x27;adam&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(max_iter=300, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(max_iter=300, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MLPClassifier(max_iter=300, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'activation': ['tanh', 'relu'],\n",
       "                         'alpha': [0.0001, 0.001, 0.01, 0.05],\n",
       "                         'hidden_layer_sizes': [(50, 50, 50), (50, 100, 50),\n",
       "                                                (10, 10)],\n",
       "                         'learning_rate': ['constant', 'adaptive'],\n",
       "                         'solver': ['sgd', 'adam']})"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (10,10)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, .001, 0.01, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "nn_2 = MLPClassifier(max_iter=300, random_state=42)\n",
    "\n",
    "nn_grid = GridSearchCV(nn_2, param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the model to the data\n",
    "nn_grid.fit(nn_x, nn_y)  # replace X and y with your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Try to add an `import pycuda` line at the top ...\n",
       "1       Hello, our project has begun to fall a little ...\n",
       "2       Picking up your challenge. You a big fan of sk...\n",
       "3       @Herbert: Still I think your answer is very co...\n",
       "4       Thanks for continuing to look over the article...\n",
       "                              ...                        \n",
       "4927    You never mentioned how far it is to work? How...\n",
       "4928    Why are the results bad? Can you elaborate on ...\n",
       "4929    Thank you, after some experimenting, this seem...\n",
       "4930    Why are you using that in the first place? Why...\n",
       "4931    Why on earth would that make for bad chicken s...\n",
       "Name: text, Length: 4932, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([ 0.03849498,  0.29648408,  0.06791625, -0.03388536,  0.10964056,\n",
       "              -0.29727167,  0.05290221,  0.64719325, -0.21412535, -0.07203906,\n",
       "              -0.05511004, -0.22657014,  0.02251264,  0.25524318, -0.07646068,\n",
       "              -0.18734314,  0.20749038, -0.24285263, -0.18108326, -0.6431815 ,\n",
       "               0.14762792,  0.14411975,  0.13561076, -0.05235285, -0.12610151,\n",
       "              -0.16299121, -0.1402613 , -0.14767891, -0.33188948,  0.25540295,\n",
       "               0.52841353,  0.0082042 ,  0.16849895, -0.58971983, -0.2134884 ,\n",
       "               0.6076413 ,  0.13525869, -0.20679975, -0.27537018, -0.5345579 ,\n",
       "              -0.06494079, -0.31286648, -0.13413282,  0.06689253,  0.3603256 ,\n",
       "              -0.20546953, -0.18698806, -0.19649453,  0.22384594,  0.05041104,\n",
       "               0.141752  , -0.20044357, -0.1835096 , -0.06338381, -0.24227352,\n",
       "               0.07340314,  0.1605139 , -0.03571523, -0.55876875, -0.10154375,\n",
       "               0.22573948, -0.06322338,  0.12371819, -0.07308272, -0.44749603,\n",
       "               0.34716415,  0.24711742,  0.28534004, -0.6156655 ,  0.32512718,\n",
       "              -0.21270795, -0.04256203,  0.29495132, -0.04210508,  0.33737707,\n",
       "               0.15164427, -0.00777507,  0.01694297, -0.33523282,  0.13208945,\n",
       "              -0.19011068, -0.24373536, -0.5648253 ,  0.52745014, -0.341728  ,\n",
       "              -0.07315937,  0.14186375,  0.5747232 ,  0.37954172,  0.05757968,\n",
       "               0.43877867,  0.3485278 ,  0.10236654,  0.01831306,  0.5243274 ,\n",
       "               0.14226463, -0.01714825, -0.20891862,  0.1465077 , -0.15478462],\n",
       "             dtype=float32)                                                    ,\n",
       "       array([-0.11621226,  0.3075991 ,  0.05338153, -0.08689754,  0.1673172 ,\n",
       "              -0.3567778 ,  0.06716333,  0.6675303 , -0.26541007, -0.12033794,\n",
       "              -0.07616907, -0.2564381 , -0.00502574,  0.1787267 ,  0.06383854,\n",
       "              -0.28211415,  0.18312338, -0.26716533, -0.19122586, -0.71038   ,\n",
       "               0.07820265,  0.11309191,  0.13464215, -0.01747559, -0.10223576,\n",
       "              -0.14855462, -0.12337612, -0.21121436, -0.32288587,  0.22629918,\n",
       "               0.4778094 , -0.0170703 ,  0.12896933, -0.47068658, -0.21742435,\n",
       "               0.61499476,  0.0682321 , -0.17562185, -0.17282653, -0.49945807,\n",
       "               0.04156217, -0.3906329 , -0.1234688 ,  0.1131739 ,  0.38039613,\n",
       "              -0.20252825, -0.20715779, -0.15740702,  0.17796409,  0.0289834 ,\n",
       "               0.1763008 , -0.21276468, -0.06938709, -0.00616181, -0.32927504,\n",
       "               0.13482729,  0.22158234, -0.09748601, -0.46770135, -0.08493496,\n",
       "               0.2682025 , -0.07673033,  0.15239592, -0.07499602, -0.43939832,\n",
       "               0.3647233 ,  0.26063597,  0.41448048, -0.6067525 ,  0.33199272,\n",
       "              -0.18238105,  0.07172105,  0.25710523,  0.02384759,  0.35860914,\n",
       "               0.19896406,  0.05107702,  0.07176318, -0.30869234,  0.09212727,\n",
       "              -0.12787616, -0.25756434, -0.46559852,  0.45715347, -0.20778617,\n",
       "              -0.01224545,  0.11381665,  0.48866257,  0.34263027, -0.0064197 ,\n",
       "               0.5227107 ,  0.29627   ,  0.07654624,  0.06674171,  0.5625536 ,\n",
       "               0.23609684,  0.08257046, -0.2604897 ,  0.12769003, -0.151739  ],\n",
       "             dtype=float32)                                                    ,\n",
       "       array([-0.00270662,  0.36482814,  0.06751088, -0.02727734,  0.15789773,\n",
       "              -0.37555808,  0.09228349,  0.7271752 , -0.2784192 , -0.0975102 ,\n",
       "              -0.04373763, -0.3177698 ,  0.0201008 ,  0.24955067, -0.02540782,\n",
       "              -0.23975834,  0.18481496, -0.26347035, -0.16115332, -0.71408516,\n",
       "               0.15244547,  0.12784363,  0.1475098 , -0.06522162, -0.1656506 ,\n",
       "              -0.13278581, -0.1526216 , -0.20116605, -0.37571257,  0.23811963,\n",
       "               0.51484233, -0.01647901,  0.20051818, -0.5714556 , -0.23609899,\n",
       "               0.64090985,  0.13165687, -0.17434624, -0.26962143, -0.56017065,\n",
       "              -0.04409722, -0.34345445, -0.14831558,  0.12374514,  0.36683458,\n",
       "              -0.24534726, -0.18309517, -0.19939396,  0.25920042,  0.05759653,\n",
       "               0.14462124, -0.25536844, -0.13083014, -0.05497059, -0.27509677,\n",
       "               0.08686212,  0.20729399, -0.02510832, -0.5496985 , -0.09956265,\n",
       "               0.23328085, -0.05489919,  0.13333043, -0.08118029, -0.47723633,\n",
       "               0.37129432,  0.23592618,  0.35702017, -0.7073201 ,  0.34725204,\n",
       "              -0.2262744 ,  0.00398314,  0.3646643 , -0.06022025,  0.381382  ,\n",
       "               0.17642866, -0.00998412,  0.02968159, -0.3385333 ,  0.10812704,\n",
       "              -0.21181442, -0.26025537, -0.59377116,  0.50411034, -0.32301608,\n",
       "              -0.0841189 ,  0.13935222,  0.6215882 ,  0.4637482 ,  0.03386087,\n",
       "               0.46322852,  0.40197453,  0.10103593,  0.03928864,  0.6494604 ,\n",
       "               0.17503107,  0.03535602, -0.25675943,  0.16993904, -0.18851493],\n",
       "             dtype=float32)                                                    ,\n",
       "       ...,\n",
       "       array([-0.03418075,  0.2774171 ,  0.07000836, -0.0552598 ,  0.12323826,\n",
       "              -0.30625436,  0.05481304,  0.5986111 , -0.20580132, -0.09545707,\n",
       "              -0.04853363, -0.22391918, -0.00686514,  0.20280431, -0.02566859,\n",
       "              -0.20829563,  0.18858124, -0.23622355, -0.17136605, -0.61795974,\n",
       "               0.10156315,  0.12511523,  0.12636179, -0.02764791, -0.106665  ,\n",
       "              -0.14222756, -0.13428922, -0.16401495, -0.29055747,  0.21672712,\n",
       "               0.46711466,  0.00620431,  0.14385882, -0.4899273 , -0.19616   ,\n",
       "               0.5575162 ,  0.10497643, -0.17315578, -0.19988403, -0.47339594,\n",
       "              -0.00863883, -0.31416485, -0.12061518,  0.07499211,  0.33501852,\n",
       "              -0.18734738, -0.17380702, -0.15748848,  0.19257079,  0.0413911 ,\n",
       "               0.14722422, -0.19693947, -0.11046796, -0.02840384, -0.2681135 ,\n",
       "               0.09013909,  0.1852577 , -0.04303333, -0.47490156, -0.08157411,\n",
       "               0.22295663, -0.06111719,  0.12523042, -0.07043719, -0.40823746,\n",
       "               0.31237954,  0.24151406,  0.30764604, -0.56068283,  0.30342266,\n",
       "              -0.18753432,  0.01056735,  0.2614275 , -0.01534826,  0.3164633 ,\n",
       "               0.15243539,  0.00627754,  0.03834468, -0.29995176,  0.0999759 ,\n",
       "              -0.1676808 , -0.22693081, -0.47767204,  0.46073365, -0.2668987 ,\n",
       "              -0.03840069,  0.11849135,  0.50518394,  0.33288136,  0.03519571,\n",
       "               0.44230512,  0.30673227,  0.08613786,  0.03921458,  0.50041354,\n",
       "               0.16812404,  0.01889038, -0.22256273,  0.13107127, -0.1306482 ],\n",
       "             dtype=float32)                                                    ,\n",
       "       array([-0.19396403,  0.44235954,  0.02410113, -0.09973348,  0.25169292,\n",
       "              -0.46592394,  0.15938863,  0.8328913 , -0.38486922, -0.18372068,\n",
       "              -0.08649446, -0.43064046,  0.01157209,  0.19180416,  0.17416045,\n",
       "              -0.39456144,  0.16906317, -0.28442103, -0.19924852, -0.8686541 ,\n",
       "               0.08335779,  0.04149172,  0.13279982, -0.02763369, -0.13228506,\n",
       "              -0.11393009, -0.15950087, -0.31447783, -0.38133284,  0.2049859 ,\n",
       "               0.45010996, -0.06455597,  0.15626591, -0.48395124, -0.24046235,\n",
       "               0.72946197,  0.07046811, -0.10790037, -0.16113953, -0.5370308 ,\n",
       "               0.02493411, -0.45899057, -0.14475048,  0.21796496,  0.4152483 ,\n",
       "              -0.28419003, -0.22518668, -0.10670501,  0.24799235,  0.07249554,\n",
       "               0.19399235, -0.24317761, -0.01096589, -0.02292084, -0.423971  ,\n",
       "               0.1447434 ,  0.33619684, -0.09341198, -0.46054468, -0.07359707,\n",
       "               0.27336282, -0.09437721,  0.17221062, -0.09777901, -0.49746424,\n",
       "               0.42228675,  0.31389773,  0.57499325, -0.76418936,  0.4193976 ,\n",
       "              -0.15199637,  0.1254867 ,  0.3168587 ,  0.06340818,  0.45778188,\n",
       "               0.21129258,  0.08592083,  0.13124537, -0.30619282,  0.08941367,\n",
       "              -0.18430538, -0.2733665 , -0.47575125,  0.39058584, -0.1625485 ,\n",
       "              -0.05278699,  0.13171211,  0.5372586 ,  0.4850994 , -0.04807521,\n",
       "               0.58954966,  0.36039874,  0.13121404,  0.09360309,  0.7405978 ,\n",
       "               0.31020576,  0.19496794, -0.35642076,  0.15882376, -0.17999169],\n",
       "             dtype=float32)                                                    ,\n",
       "       array([-0.1009762 ,  0.2849275 ,  0.06993384, -0.07139986,  0.13099998,\n",
       "              -0.35281646,  0.04433755,  0.65102607, -0.23973098, -0.13695788,\n",
       "              -0.08369906, -0.21856165, -0.01098922,  0.18941036,  0.04726055,\n",
       "              -0.2796986 ,  0.18574676, -0.29721   , -0.18732783, -0.6949602 ,\n",
       "               0.07470262,  0.13600717,  0.12480381,  0.00215367, -0.09023675,\n",
       "              -0.16121802, -0.14340208, -0.19399439, -0.27703595,  0.22222188,\n",
       "               0.47999734, -0.00501987,  0.13301383, -0.48976693, -0.22002694,\n",
       "               0.63314664,  0.07137673, -0.21772544, -0.1848971 , -0.51275426,\n",
       "               0.02091879, -0.38147846, -0.11378516,  0.07637917,  0.38084832,\n",
       "              -0.17750005, -0.21964945, -0.17455116,  0.15952255,  0.04540081,\n",
       "               0.16564606, -0.17960611, -0.10257981,  0.00796545, -0.32570267,\n",
       "               0.11817425,  0.20114727, -0.11051663, -0.4670021 , -0.07662622,\n",
       "               0.25740194, -0.06806934,  0.1387176 , -0.084277  , -0.4424118 ,\n",
       "               0.33942404,  0.28111935,  0.39350045, -0.5685528 ,  0.31956658,\n",
       "              -0.1725386 ,  0.05408107,  0.21715371,  0.0565659 ,  0.36016515,\n",
       "               0.1740314 ,  0.03004269,  0.07134014, -0.31756228,  0.12862484,\n",
       "              -0.12546325, -0.23112838, -0.44363454,  0.48297745, -0.2235323 ,\n",
       "               0.00953162,  0.1382792 ,  0.46910298,  0.31551346,  0.01949539,\n",
       "               0.52631056,  0.267135  ,  0.07218207,  0.08385721,  0.49650395,\n",
       "               0.24367815,  0.05950032, -0.23431137,  0.10051317, -0.11941233],\n",
       "             dtype=float32)                                                    ],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polite['text_avg_embedding'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(50, 50, 50), max_iter=300)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(50, 50, 50), max_iter=300)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(50, 50, 50), max_iter=300)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_nn_params = nn_grid.best_params_\n",
    "print(\"Best parameters:\", best_nn_params)\n",
    "\n",
    "best_nn = MLPClassifier(**best_nn_params, max_iter=300)\n",
    "best_nn.fit(nn_x, nn_y)  # replace X and y with your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1769  697]\n",
      " [1132 1334]]\n"
     ]
    }
   ],
   "source": [
    "pred_nn_y = best_nn.predict(nn_x)\n",
    "cm = confusion_matrix(nn_y, pred_nn_y)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after some minor hyperparameter searching, the neural network still performs poorly with the embeddings I used. This goes to show that the quality of input matters just as much as the model predicting the output. My best guess to improve the input quality is to use a higher quality pre-trained embedding from online, as opposed to a \"word2vectorization\" of the words in the politeness dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
